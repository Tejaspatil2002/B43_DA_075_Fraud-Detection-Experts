{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6dece08-42c3-4aef-a8a4-a5b5a5c71252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting prawcore<3,>=2.4 (from praw)\n",
      "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting update_checker>=0.18 (from praw)\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.8.30)\n",
      "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
      "Downloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
      "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Installing collected packages: update_checker, prawcore, praw\n",
      "Successfully installed praw-7.8.1 prawcore-2.4.0 update_checker-0.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9845df-7e15-41fd-937b-933f43ddc149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Reddit API credentials\n",
    "CLIENT_ID = \"1OGPJ-KHnQSCWKGg-N5StQ\"\n",
    "CLIENT_SECRET = \"w7JLrIPYRJlqxpPPys_syEWHsZ-UoA\"\n",
    "USER_AGENT = \"Project:v1.0\"\n",
    "\n",
    "# Authenticate with Reddit\n",
    "reddit = praw.Reddit(\n",
    "    client_id=CLIENT_ID,\n",
    "    client_secret=CLIENT_SECRET,\n",
    "    user_agent=USER_AGENT\n",
    ")\n",
    "\n",
    "# Define subreddits and keywords\n",
    "subreddits = [\"environment\", \"climate\", \"sustainability\", \"science\", \"news\"]\n",
    "keywords = [\"climate change\", \"global warming\", \"sustainability\", \"renewable energy\", \"carbon footprint\"]\n",
    "\n",
    "# Initialize variables for pagination\n",
    "post_data = []\n",
    "max_posts = 100000  # Increase dataset size for better prediction\n",
    "batch_size = 100  # Number of posts per request\n",
    "\n",
    "# Fetch historical posts with pagination\n",
    "for sub in subreddits:\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    for keyword in keywords:\n",
    "        try:\n",
    "            # Get historical posts using `new` and `top`\n",
    "            for post in subreddit.new(limit=max_posts):\n",
    "                created_at = datetime.utcfromtimestamp(post.created_utc)\n",
    "                year = created_at.year\n",
    "                month = created_at.month\n",
    "                quarter = (month - 1) // 3 + 1\n",
    "                \n",
    "                # Extract hashtags from title and text\n",
    "                hashtags = re.findall(r\"#\\w+\", post.title + \" \" + post.selftext)\n",
    "                \n",
    "                # Determine engagement level\n",
    "                engagement_score = post.score + post.num_comments\n",
    "                if engagement_score > 1000:\n",
    "                    engagement_level = \"High\"\n",
    "                elif engagement_score > 100:\n",
    "                    engagement_level = \"Medium\"\n",
    "                else:\n",
    "                    engagement_level = \"Low\"\n",
    "                \n",
    "                post_data.append({\n",
    "                    \"Post_ID\": post.id,\n",
    "                    \"Platform\": \"Reddit\",\n",
    "                    \"Hashtag\": \", \".join(hashtags) if hashtags else None,\n",
    "                    \"Content_Type\": \"Post\",\n",
    "                    \"Likes\": post.score,\n",
    "                    \"Comments\": post.num_comments,\n",
    "                    \"Engagement_Level\": engagement_level,\n",
    "                    \"Title\": post.title,\n",
    "                    \"Text\": post.selftext,\n",
    "                    \"Created_At\": created_at.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                    \"Year\": year,\n",
    "                    \"Month\": month,\n",
    "                    \"Quarter\": quarter,\n",
    "                    \"Subreddit\": post.subreddit.display_name,\n",
    "                    \"Keyword\": keyword\n",
    "                })\n",
    "\n",
    "            print(f\"Collected {len(post_data)} posts so far from r/{sub} on '{keyword}'...\")\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping {sub} for '{keyword}': {e}\")\n",
    "            continue\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_reddit = pd.DataFrame(post_data)\n",
    "\n",
    "# Save to CSV\n",
    "df_reddit.to_csv(\"reddit_historical_data.csv\", index=False)\n",
    "print(f\"âœ… Scraped {len(df_reddit)} Reddit posts successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2367c141-c72f-4a43-9d53-06fb83ecce11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
