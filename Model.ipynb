{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40ff10df-6d64-4289-9830-9a1476279c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9811422413793104\n",
      "Mean Squared Error: 0.023706896551724137\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      0.99      1.00       616\n",
      "         Low       0.98      0.99      0.98      2052\n",
      "      Medium       0.98      0.95      0.97      1044\n",
      "\n",
      "    accuracy                           0.98      3712\n",
      "   macro avg       0.98      0.98      0.98      3712\n",
      "weighted avg       0.98      0.98      0.98      3712\n",
      "\n",
      "Predicted future engagement level: ['Medium']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('reddit_historical_data.csv')\n",
    "\n",
    "# Drop irrelevant columns\n",
    "df_clean = df.drop(columns=[\"Post_ID\", \"Platform\", \"Hashtag\", \"Created_At\", \"Text\"])\n",
    "\n",
    "# Fill missing values\n",
    "df_clean.fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in [\"Content_Type\", \"Subreddit\", \"Keyword\"]:\n",
    "    le = LabelEncoder()\n",
    "    df_clean[col] = le.fit_transform(df_clean[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode target variable\n",
    "le_target = LabelEncoder()\n",
    "df_clean[\"Engagement_Level\"] = le_target.fit_transform(df_clean[\"Engagement_Level\"])\n",
    "\n",
    "# TF-IDF vectorization for Title\n",
    "tfidf = TfidfVectorizer(max_features=300, stop_words='english', ngram_range=(1,2))\n",
    "title_tfidf = tfidf.fit_transform(df_clean[\"Title\"])\n",
    "\n",
    "df_clean.drop(columns=[\"Title\"], inplace=True)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X = df_clean.drop(columns=[\"Engagement_Level\"])\n",
    "y = df_clean[\"Engagement_Level\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply TF-IDF transformation to train and test sets\n",
    "X_train_tfidf = tfidf.transform(df.loc[X_train.index, \"Title\"])\n",
    "X_test_tfidf = tfidf.transform(df.loc[X_test.index, \"Title\"])\n",
    "\n",
    "# Combine TF-IDF features with numerical features\n",
    "X_train_combined = hstack([X_train, X_train_tfidf])\n",
    "X_test_combined = hstack([X_test, X_test_tfidf])\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "X_test_scaled = scaler.transform(X_test_combined)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "n_components = min(100, X_train_scaled.shape[1])  # Limit to 100 or total available features\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Train RandomForestClassifier on PCA-transformed data\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)\n",
    "rf_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred, target_names=le_target.classes_)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "\n",
    "# Predict future engagement levels (random example for demonstration)\n",
    "future_data = np.random.rand(1, X_train_scaled.shape[1])  # Generate random data\n",
    "future_data_pca = pca.transform(future_data)\n",
    "future_prediction = rf_model.predict(future_data_pca)\n",
    "print(\"Predicted future engagement level:\", le_target.inverse_transform(future_prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d0b52-c08e-4b14-8b51-c7aedf63b2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fab9e2-a3af-4ba7-95f1-f6d4a53810c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c9cc8-8d0f-4fb8-91bd-405379bb459b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c099af-3d92-422f-b939-ce28d817e9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
